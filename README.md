# Meta Learning

> ### keywords
>
> Meta-Classifier, Meta-Learning, Few-Shot Learning,  Learning to learn

* Concept
  * [CS330: Deep Multi-Task and Meta Learning](https://github.com/abooundev/meta_learning/blob/main/CS330_Deep%20Multi-Task%20and%20Meta%20Learning.md)
  * [바로 AI 아카데미 4월 오픈 클래스 | Deep Meta Learning - Part 1](https://youtu.be/EcSp9FV7fpY)
  * [바로 AI 아카데미 4월 오픈 클래스 | Deep Meta Learning - Part 2](https://youtu.be/-aAR6PqshK8)
  * [KAIST NeuroAI JC_#1 Meta Learning (편집본)](https://youtu.be/Izqod36syY8)



* Survey
  * [Hospedales, Timothy, et al. "Meta-learning in neural networks: A survey." *arXiv preprint arXiv:2004.05439* (2020). ](https://arxiv.org/pdf/2004.05439.pdf)
  * [Vanschoren, Joaquin. "Meta-learning: A survey." *arXiv preprint arXiv:1810.03548* (2018).](https://arxiv.org/pdf/1810.03548.pdf)


* Awesome repo
  * https://awesomeopensource.com/projects/few-shot-learning/meta-learning
  * https://awesomeopensource.com/projects/few-shot-learning
    

* Torchmeta
  * A collection of extensions and data-loaders for few-shot learning & meta-learning in [PyTorch](https://pytorch.org/). Torchmeta contains popular meta-learning benchmarks, fully compatible with both [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html) and PyTorch's [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).
  * https://tristandeleu.github.io/pytorch-meta/
  * Datasets available
    * Few-shot regression (toy problems):
      - Sine waves ([Finn et al., 2017](https://arxiv.org/abs/1703.03400))
      - Harmonic functions ([Lacoste et al., 2018](https://arxiv.org/abs/1806.07528))
      - Sinusoid & lines ([Finn et al., 2018](https://arxiv.org/abs/1806.02817))

    * Few-shot classification (image classification):
      - Omniglot ([Lake et al., 2015](https://www.sciencemag.org/content/350/6266/1332.short)[, 2019](https://arxiv.org/abs/1902.03477))
      - Mini-ImageNet ([Vinyals et al., 2016](https://arxiv.org/abs/1606.04080), [Ravi et al., 2017](https://openreview.net/forum?id=rJY0-Kcll))
      - Tiered-ImageNet ([Ren et al., 2018](https://arxiv.org/abs/1803.00676))
      - CIFAR-FS ([Bertinetto et al., 2018](https://arxiv.org/abs/1805.08136))
      - Fewshot-CIFAR100 ([Oreshkin et al., 2018](https://arxiv.org/abs/1805.10123))
      - Caltech-UCSD Birds ([Hilliard et al., 2019](https://arxiv.org/abs/1802.04376), [Wah et al., 2019](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html))
      - Double MNIST ([Sun, 2019](https://github.com/shaohua0116/MultiDigitMNIST))
      - Triple MNIST ([Sun, 2019](https://github.com/shaohua0116/MultiDigitMNIST))

    * Few-shot segmentation (semantic segmentation):
      - Pascal5i 1-way Setup

        


* 참고 강의
  * [Learning to learn unlearned feature for segmentation](https://tv.naver.com/v/5581357)
  * [Gradient-based Meta-learning with learned layerwise subspace and metric](https://youtu.be/bMpdIPKEa7E)







## SKT
*  출처: https://www.skt.ai/kr/ai_x/index.do
![img](https://lh6.googleusercontent.com/2Jg6xaYjdFJrHAd72pvfA-oWtedS9jmfEmt34Avo7DmGWcpdk7zptFtxyvC-VvuXlvBLL3ISlGAAtF5FfYJEnixn5mZ0SlRQ95LjBfwZewRUSmzJd4PIzzNyPl6jgcU-MvdYcLL8Y48)

![img](https://lh4.googleusercontent.com/6cD_BeVCFv-nwJQ_HOAtIqWfbQg183yLuQ6RWRP5tb9dQcAqcyJqr_66vG_PyipGTIvgM6glz_XIdnvj8urZzlolARp0gkoHAn_bTJzBsHJ4j-3VEl8LHK_hl73WqhwespSRULpG2ys)

![img](https://lh4.googleusercontent.com/iMHofx8_b6DdoT4quqOpzNhRbfi4BJ8jWQYlmqs6N0Fx49v4i1XWyW9KwuL-SqSDPMR8HglFvaYRA4Ke8DSPCsI_qAMqQFtOcAe5su836Jz5UVvXRDSAK4_ofcu2WQ7QHyfMWbqdHSs)

